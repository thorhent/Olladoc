<p align="center">
  <img src="data/logo.svg" width="150" alt="Olladoc Logo"/>
</p>

<h1 align="center">┖ Olladoc</h1>

<p align="center">
  Aplicaci贸n m茅dica moderna desarrollada con <b>GTK 4</b> y <b>libadwaita</b>, dise帽ada para generar historias cl铆nicas profesionales con entrada por voz e inteligencia artificial.
</p>

<p align="center">
  <img src="data/olladoc-img1.png" width="600" alt="Captura de pantalla principal"/>
</p>

---

##  Caracter铆sticas destacadas

-  Entrada por voz y texto para anamnesis r谩pida
-  Generaci贸n de historia cl铆nica en PDF
-  Orientaci贸n diagn贸stica con IA local (Ollama + Llama3)
- ┖ Flujo cl铆nico profesional con AdwNavigationView
-  Interfaz moderna con dise帽o limpio y responsivo
-  Compatible con Flatpak y Flathub

---

##  Capturas de pantalla

| Inicio | Consulta |
|--------|----------|
| ![Home](data/home.png) | ![Consulta](data/consulta.png) |

---

## И C贸mo ejecutar localmente (Flatpak)

###  1. Construcci贸n, prueba e instalaci贸n

Para construir el proyecto Flatpak desde cero y limpiar cualquier compilaci贸n anterior, usa el siguiente comando:

```bash
flatpak-builder --force-clean build-dir com.github.thorhent.Olladoc
```

Una vez que el proyecto est茅 construido, puedes ejecutar la aplicaci贸n directamente desde el directorio de compilaci贸n:

```bash
flatpak-builder --run build-dir com.github.thorhent.Olladoc olladoc

```


Para instalar el proyecto Flatpak en tu sistema (solo para el usuario actual) y limpiar cualquier compilaci贸n anterior antes de la instalaci贸n:

```bash
flatpak-builder --user --force-clean --install build-dir com.github.thorhent.Olladoc

```

---

##  C贸mo instalar Ollama y modelos

Olladoc depende de [Ollama](https://ollama.com/) para ejecutar modelos de lenguaje localmente.  
A continuaci贸n se explican los pasos de instalaci贸n en Fedora (recomendado) y en Ubuntu/Debian.

---

###  Fedora (42)

```bash
sudo dnf install ollama
```

###  Ubuntu/Debian 

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

---

###  Instalar modelos Ollama

Recomendados y probados en computadora sin GPU con **8 GB de RAM**:  
- `phi3.5:3.8b`  
- `gemma3:4b`  
- `llama3.2:3b`

```bash
ollama pull phi3.5:3.8b
ollama pull gemma3:4b
ollama pull llama3.2:3b
```


